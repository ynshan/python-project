{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e86d6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6387b450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.23995375260710716\n",
      "Test acc: 0.03333333333333333\n",
      "------------------\n",
      "Epoch: 1, Loss: 0.2095555067062378\n",
      "Test acc: 0.36666666666666664\n",
      "------------------\n",
      "Epoch: 2, Loss: 0.19522004202008247\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 3, Loss: 0.18381337076425552\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 4, Loss: 0.17402884736657143\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 5, Loss: 0.16576289758086205\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 6, Loss: 0.15881287306547165\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 7, Loss: 0.15295101329684258\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 8, Loss: 0.14796840772032738\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 9, Loss: 0.14369017258286476\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 10, Loss: 0.13997616060078144\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 11, Loss: 0.13671627454459667\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 12, Loss: 0.13382457941770554\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 13, Loss: 0.1312339175492525\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 14, Loss: 0.12889158353209496\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 15, Loss: 0.12675597332417965\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 16, Loss: 0.12479390762746334\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 17, Loss: 0.12297877296805382\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 18, Loss: 0.12128904275596142\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 19, Loss: 0.1197071522474289\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 20, Loss: 0.11821867898106575\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 21, Loss: 0.11681167036294937\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 22, Loss: 0.11547619290649891\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 23, Loss: 0.11420387774705887\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 24, Loss: 0.1129877008497715\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 25, Loss: 0.11182167753577232\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 26, Loss: 0.11070070788264275\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 27, Loss: 0.10962040722370148\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 28, Loss: 0.10857702605426311\n",
      "Test acc: 0.6333333333333333\n",
      "------------------\n",
      "Epoch: 29, Loss: 0.10756727494299412\n",
      "Test acc: 0.7\n",
      "------------------\n",
      "Epoch: 30, Loss: 0.10658832266926765\n",
      "Test acc: 0.7333333333333333\n",
      "------------------\n",
      "Epoch: 31, Loss: 0.1056376900523901\n",
      "Test acc: 0.7333333333333333\n",
      "------------------\n",
      "Epoch: 32, Loss: 0.10471321269869804\n",
      "Test acc: 0.7333333333333333\n",
      "------------------\n",
      "Epoch: 33, Loss: 0.10381295904517174\n",
      "Test acc: 0.7666666666666667\n",
      "------------------\n",
      "Epoch: 34, Loss: 0.10293524153530598\n",
      "Test acc: 0.7666666666666667\n",
      "------------------\n",
      "Epoch: 35, Loss: 0.10207856073975563\n",
      "Test acc: 0.7666666666666667\n",
      "------------------\n",
      "Epoch: 36, Loss: 0.10124157927930355\n",
      "Test acc: 0.7666666666666667\n",
      "------------------\n",
      "Epoch: 37, Loss: 0.10042310506105423\n",
      "Test acc: 0.7666666666666667\n",
      "------------------\n",
      "Epoch: 38, Loss: 0.09962207265198231\n",
      "Test acc: 0.7666666666666667\n",
      "------------------\n",
      "Epoch: 39, Loss: 0.09883752837777138\n",
      "Test acc: 0.7666666666666667\n",
      "------------------\n",
      "Epoch: 40, Loss: 0.0980685967952013\n",
      "Test acc: 0.7666666666666667\n",
      "------------------\n",
      "Epoch: 41, Loss: 0.09731450304389\n",
      "Test acc: 0.7666666666666667\n",
      "------------------\n",
      "Epoch: 42, Loss: 0.09657453559339046\n",
      "Test acc: 0.7666666666666667\n",
      "------------------\n",
      "Epoch: 43, Loss: 0.09584805183112621\n",
      "Test acc: 0.7666666666666667\n",
      "------------------\n",
      "Epoch: 44, Loss: 0.09513446874916553\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 45, Loss: 0.09443324245512486\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 46, Loss: 0.09374388866126537\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 47, Loss: 0.09306594915688038\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 48, Loss: 0.09239899925887585\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 49, Loss: 0.09174267575144768\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 50, Loss: 0.09109660610556602\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 51, Loss: 0.09046045877039433\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 52, Loss: 0.0898339245468378\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 53, Loss: 0.08921671658754349\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 54, Loss: 0.08860857412219048\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 55, Loss: 0.08800922892987728\n",
      "Test acc: 0.8\n",
      "------------------\n",
      "Epoch: 56, Loss: 0.087418457493186\n",
      "Test acc: 0.8333333333333334\n",
      "------------------\n",
      "Epoch: 57, Loss: 0.08683602884411812\n",
      "Test acc: 0.8333333333333334\n",
      "------------------\n",
      "Epoch: 58, Loss: 0.08626173250377178\n",
      "Test acc: 0.8333333333333334\n",
      "------------------\n",
      "Epoch: 59, Loss: 0.08569536916911602\n",
      "Test acc: 0.8333333333333334\n",
      "------------------\n",
      "Epoch: 60, Loss: 0.08513675443828106\n",
      "Test acc: 0.8333333333333334\n",
      "------------------\n",
      "Epoch: 61, Loss: 0.08458570018410683\n",
      "Test acc: 0.8333333333333334\n",
      "------------------\n",
      "Epoch: 62, Loss: 0.08404204063117504\n",
      "Test acc: 0.8666666666666667\n",
      "------------------\n",
      "Epoch: 63, Loss: 0.08350560814142227\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 64, Loss: 0.08297624997794628\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 65, Loss: 0.08245382737368345\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 66, Loss: 0.08193818014115095\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 67, Loss: 0.08142918068915606\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 68, Loss: 0.08092669863253832\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 69, Loss: 0.08043060265481472\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 70, Loss: 0.07994077168405056\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 71, Loss: 0.07945709023624659\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 72, Loss: 0.0789794409647584\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 73, Loss: 0.07850773073732853\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 74, Loss: 0.07804181892424822\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 75, Loss: 0.07758164126425982\n",
      "Test acc: 0.9\n",
      "------------------\n",
      "Epoch: 76, Loss: 0.0771270701661706\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 77, Loss: 0.07667802553623915\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 78, Loss: 0.07623439934104681\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 79, Loss: 0.07579611148685217\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 80, Loss: 0.07536306884139776\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 81, Loss: 0.07493517827242613\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 82, Loss: 0.07451235968619585\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 83, Loss: 0.07409453392028809\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 84, Loss: 0.0736816180869937\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 85, Loss: 0.07327353209257126\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 86, Loss: 0.07287020143121481\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 87, Loss: 0.0724715543910861\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 88, Loss: 0.07207750249654055\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 89, Loss: 0.07168798986822367\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 90, Loss: 0.07130294572561979\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 91, Loss: 0.07092228718101978\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 92, Loss: 0.07054595276713371\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 93, Loss: 0.07017389591783285\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 94, Loss: 0.06980603374540806\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 95, Loss: 0.06944230105727911\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 96, Loss: 0.06908264942467213\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 97, Loss: 0.06872699782252312\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 98, Loss: 0.0683753089979291\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 99, Loss: 0.06802750751376152\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 100, Loss: 0.06768354866653681\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 101, Loss: 0.06734336912631989\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 102, Loss: 0.06700691115111113\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 103, Loss: 0.06667412631213665\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 104, Loss: 0.06634496431797743\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 105, Loss: 0.06601936463266611\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 106, Loss: 0.06569727789610624\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 07:38:49.239391: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107, Loss: 0.06537865567952394\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 108, Loss: 0.06506344489753246\n",
      "Test acc: 0.9333333333333333\n",
      "------------------\n",
      "Epoch: 109, Loss: 0.06475160270929337\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 110, Loss: 0.06444308161735535\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 111, Loss: 0.0641378303989768\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 112, Loss: 0.0638358062133193\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 113, Loss: 0.06353696342557669\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 114, Loss: 0.06324125360697508\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 115, Loss: 0.06294863298535347\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 116, Loss: 0.06265906058251858\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 117, Loss: 0.06237250380218029\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 118, Loss: 0.06208890303969383\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 119, Loss: 0.06180822476744652\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 120, Loss: 0.06153044104576111\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 121, Loss: 0.06125549413263798\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 122, Loss: 0.060983351431787014\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 123, Loss: 0.06071397289633751\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 124, Loss: 0.060447328723967075\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 125, Loss: 0.060183377005159855\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 126, Loss: 0.05992208421230316\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 127, Loss: 0.05966340750455856\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 128, Loss: 0.05940731056034565\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 129, Loss: 0.059153773821890354\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 130, Loss: 0.05890274420380592\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 131, Loss: 0.05865420587360859\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 132, Loss: 0.05840811040252447\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 133, Loss: 0.058164420537650585\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 134, Loss: 0.05792313814163208\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 135, Loss: 0.05768420081585646\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 136, Loss: 0.0574475871399045\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 137, Loss: 0.057213264517486095\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 138, Loss: 0.05698120594024658\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 139, Loss: 0.05675137788057327\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 140, Loss: 0.0565237570554018\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 141, Loss: 0.05629830714315176\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 142, Loss: 0.05607500299811363\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 143, Loss: 0.05585381668061018\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 144, Loss: 0.055634728632867336\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 145, Loss: 0.055417703464627266\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 146, Loss: 0.055202716030180454\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 147, Loss: 0.054989744909107685\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 148, Loss: 0.05477875377982855\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 149, Loss: 0.05456972774118185\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 150, Loss: 0.054362641647458076\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 151, Loss: 0.054157462902367115\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 152, Loss: 0.053954171016812325\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 153, Loss: 0.05375275854021311\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 154, Loss: 0.05355317983776331\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 155, Loss: 0.05335541255772114\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 156, Loss: 0.053159440867602825\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 157, Loss: 0.05296525452286005\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 158, Loss: 0.05277281254529953\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 159, Loss: 0.052582092583179474\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 160, Loss: 0.05239309370517731\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 161, Loss: 0.0522057730704546\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 162, Loss: 0.0520201250910759\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 163, Loss: 0.051836119033396244\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 164, Loss: 0.05165374185889959\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 165, Loss: 0.05147297587245703\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 166, Loss: 0.05129379499703646\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 167, Loss: 0.05111617408692837\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 168, Loss: 0.05094010662287474\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 169, Loss: 0.050765568390488625\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 170, Loss: 0.05059254914522171\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 171, Loss: 0.050421019084751606\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 172, Loss: 0.05025096423923969\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 173, Loss: 0.05008236039429903\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 174, Loss: 0.04991521034389734\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 175, Loss: 0.04974947776645422\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 176, Loss: 0.04958515241742134\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 177, Loss: 0.04942221753299236\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 178, Loss: 0.04926066007465124\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 179, Loss: 0.04910046700388193\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 180, Loss: 0.04894160572439432\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 181, Loss: 0.04878407157957554\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 182, Loss: 0.04862785432487726\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 183, Loss: 0.048472935333848\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 184, Loss: 0.04831929225474596\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 185, Loss: 0.04816691391170025\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 186, Loss: 0.04801578726619482\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 187, Loss: 0.04786590300500393\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 188, Loss: 0.04771723784506321\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 189, Loss: 0.04756978526711464\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 190, Loss: 0.04742352291941643\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 191, Loss: 0.04727845173329115\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 192, Loss: 0.04713454283773899\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 193, Loss: 0.046991792507469654\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 194, Loss: 0.046850177459418774\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 195, Loss: 0.04670970141887665\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 196, Loss: 0.04657033737748861\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 197, Loss: 0.046432080678641796\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 198, Loss: 0.0462949201464653\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 199, Loss: 0.04615883342921734\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 200, Loss: 0.04602381680160761\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 201, Loss: 0.045889854431152344\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 202, Loss: 0.04575694724917412\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 203, Loss: 0.04562505800276995\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 204, Loss: 0.045494203455746174\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 205, Loss: 0.045364354737102985\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 206, Loss: 0.04523550719022751\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 207, Loss: 0.045107651501894\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 208, Loss: 0.04498076345771551\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 209, Loss: 0.044854854233562946\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 210, Loss: 0.04472990147769451\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 211, Loss: 0.044605896808207035\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 212, Loss: 0.04448282811790705\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 213, Loss: 0.044360678642988205\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 214, Loss: 0.044239453971385956\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 215, Loss: 0.044119130820035934\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 216, Loss: 0.04399970639497042\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 217, Loss: 0.04388117091730237\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 218, Loss: 0.04376351786777377\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 219, Loss: 0.043646737933158875\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 220, Loss: 0.043530809227377176\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 221, Loss: 0.04341573594138026\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 222, Loss: 0.04330150783061981\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 223, Loss: 0.04318810999393463\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 224, Loss: 0.04307554289698601\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 225, Loss: 0.04296378418803215\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 226, Loss: 0.04285283712670207\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 227, Loss: 0.04274268867447972\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 228, Loss: 0.042633332312107086\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 229, Loss: 0.042524761985987425\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 230, Loss: 0.042416971642524004\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 231, Loss: 0.04230993380770087\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 232, Loss: 0.04220366524532437\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 233, Loss: 0.042098144069314\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 234, Loss: 0.0419933763332665\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 235, Loss: 0.04188933875411749\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 236, Loss: 0.041786038782447577\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 237, Loss: 0.04168344894424081\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 238, Loss: 0.041581588331609964\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 239, Loss: 0.04148042481392622\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 240, Loss: 0.04137996444478631\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 241, Loss: 0.04128020349889994\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 242, Loss: 0.041181118693202734\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 243, Loss: 0.041082723531872034\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 244, Loss: 0.040985000785440207\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 245, Loss: 0.040887943003326654\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 246, Loss: 0.04079154692590237\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 247, Loss: 0.040695805568248034\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 248, Loss: 0.040600703563541174\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 249, Loss: 0.04050624975934625\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 250, Loss: 0.040412436705082655\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 251, Loss: 0.04031924111768603\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 252, Loss: 0.0402266732417047\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 253, Loss: 0.04013472469523549\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 254, Loss: 0.04004338150843978\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 255, Loss: 0.03995265252888203\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 256, Loss: 0.03986251587048173\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 257, Loss: 0.039772975724190474\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 258, Loss: 0.039684024173766375\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 259, Loss: 0.03959564818069339\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 260, Loss: 0.039507857989519835\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 261, Loss: 0.03942063869908452\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 262, Loss: 0.0393339772708714\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 263, Loss: 0.039247885812073946\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 264, Loss: 0.03916234103962779\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 265, Loss: 0.03907734761014581\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 266, Loss: 0.03899291064590216\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 267, Loss: 0.03890900453552604\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 268, Loss: 0.03882563067600131\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 269, Loss: 0.038742796052247286\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 270, Loss: 0.03866048343479633\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 271, Loss: 0.03857868863269687\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 272, Loss: 0.0384974149055779\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 273, Loss: 0.03841664223000407\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 274, Loss: 0.038336381316185\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 275, Loss: 0.03825662471354008\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 276, Loss: 0.038177364971488714\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 277, Loss: 0.038098601158708334\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 278, Loss: 0.038020319771021605\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 279, Loss: 0.037942527793347836\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 280, Loss: 0.037865211721509695\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 281, Loss: 0.03778837015852332\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 282, Loss: 0.037711996119469404\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 283, Loss: 0.037636096589267254\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 284, Loss: 0.037560653407126665\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 285, Loss: 0.03748566983267665\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 286, Loss: 0.03741113701835275\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 287, Loss: 0.03733706474304199\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 288, Loss: 0.037263426929712296\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 289, Loss: 0.03719024499878287\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 290, Loss: 0.037117492873221636\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 291, Loss: 0.037045175675302744\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 292, Loss: 0.036973286885768175\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 293, Loss: 0.036901837680488825\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 294, Loss: 0.03683080663904548\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 295, Loss: 0.03676018724218011\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 296, Loss: 0.03668998787179589\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 297, Loss: 0.03662020759657025\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 298, Loss: 0.0365508277900517\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 299, Loss: 0.03648185497149825\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 300, Loss: 0.036413286346942186\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 301, Loss: 0.03634511958807707\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 302, Loss: 0.036277349572628736\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 303, Loss: 0.03620996233075857\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 304, Loss: 0.03614297183230519\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 305, Loss: 0.0360763561911881\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 306, Loss: 0.03601013356819749\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 307, Loss: 0.03594428580254316\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 308, Loss: 0.035878817550837994\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 309, Loss: 0.035813717637211084\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 310, Loss: 0.03574898932129145\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 311, Loss: 0.03568462422117591\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 312, Loss: 0.035620614886283875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 313, Loss: 0.03555697714909911\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 314, Loss: 0.03549370029941201\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 315, Loss: 0.03543077129870653\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 316, Loss: 0.03536819340661168\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 317, Loss: 0.03530596382915974\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 318, Loss: 0.0352440825663507\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 319, Loss: 0.03518254170194268\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 320, Loss: 0.0351213370449841\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 321, Loss: 0.03506047511473298\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 322, Loss: 0.03499994520097971\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 323, Loss: 0.034939751494675875\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 324, Loss: 0.034879883751273155\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 325, Loss: 0.03482033917680383\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 326, Loss: 0.034761127550154924\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 327, Loss: 0.03470223490148783\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 328, Loss: 0.03464365331456065\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 329, Loss: 0.03458539070561528\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 330, Loss: 0.03452744660899043\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 331, Loss: 0.03446980286389589\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 332, Loss: 0.03441248228773475\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 333, Loss: 0.03435545228421688\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 334, Loss: 0.034298745449632406\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 335, Loss: 0.03424232127144933\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 336, Loss: 0.03418620629236102\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 337, Loss: 0.034130383748561144\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 338, Loss: 0.03407486109063029\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 339, Loss: 0.03401962388306856\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 340, Loss: 0.03396467911079526\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 341, Loss: 0.03391002304852009\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 342, Loss: 0.0338556463830173\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 343, Loss: 0.03380156448110938\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 344, Loss: 0.0337477526627481\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 345, Loss: 0.0336942276917398\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 346, Loss: 0.03364097326993942\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 347, Loss: 0.03358799545094371\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 348, Loss: 0.03353529144078493\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 349, Loss: 0.03348285472020507\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 350, Loss: 0.03343068715184927\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 351, Loss: 0.03337878594174981\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 352, Loss: 0.033327154349535704\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 353, Loss: 0.033275777008384466\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 354, Loss: 0.03322466602548957\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 355, Loss: 0.03317380929365754\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 356, Loss: 0.033123204950243235\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 357, Loss: 0.033072864171117544\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 358, Loss: 0.03302277671173215\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 359, Loss: 0.032972931396216154\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 360, Loss: 0.03292333334684372\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 361, Loss: 0.03287399327382445\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 362, Loss: 0.03282489348202944\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 363, Loss: 0.0327760367654264\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 364, Loss: 0.03272742219269276\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 365, Loss: 0.032679041381925344\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 366, Loss: 0.03263090783730149\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 367, Loss: 0.03258300479501486\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 368, Loss: 0.032535338308662176\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 369, Loss: 0.03248790139332414\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 370, Loss: 0.032440696842968464\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 371, Loss: 0.03239372558891773\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 372, Loss: 0.032346976455301046\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 373, Loss: 0.032300456892699\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 374, Loss: 0.03225415898486972\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 375, Loss: 0.032208084128797054\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 376, Loss: 0.0321622253395617\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 377, Loss: 0.0321165956556797\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 378, Loss: 0.03207118762657046\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 379, Loss: 0.03202598635107279\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 380, Loss: 0.03198100300505757\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 381, Loss: 0.03193623758852482\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 382, Loss: 0.03189167473465204\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 383, Loss: 0.03184733400121331\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 384, Loss: 0.03180319210514426\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 385, Loss: 0.031759260687977076\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 386, Loss: 0.03171553090214729\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 387, Loss: 0.031672012992203236\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 388, Loss: 0.03162869764491916\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 389, Loss: 0.03158557927235961\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 390, Loss: 0.031542662531137466\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 391, Loss: 0.031499954871833324\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 392, Loss: 0.031457425095140934\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 393, Loss: 0.03141511185094714\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 394, Loss: 0.03137297881767154\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 395, Loss: 0.03133104229345918\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 396, Loss: 0.03128930367529392\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 397, Loss: 0.03124774480238557\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 398, Loss: 0.03120638383552432\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 399, Loss: 0.031165211461484432\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 400, Loss: 0.031124225817620754\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 401, Loss: 0.0310834227129817\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 402, Loss: 0.03104280447587371\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 403, Loss: 0.031002372968941927\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 404, Loss: 0.0309621156193316\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 405, Loss: 0.03092204686254263\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 406, Loss: 0.030882149003446102\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 407, Loss: 0.03084244066849351\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 408, Loss: 0.030802902299910784\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 409, Loss: 0.030763533897697926\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 410, Loss: 0.03072434989735484\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 411, Loss: 0.03068533493205905\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 412, Loss: 0.030646495055407286\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 413, Loss: 0.03060782514512539\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 414, Loss: 0.030569323804229498\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 415, Loss: 0.03053100034594536\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 416, Loss: 0.030492830090224743\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 417, Loss: 0.03045483585447073\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 418, Loss: 0.03041700040921569\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 419, Loss: 0.030379333533346653\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 420, Loss: 0.0303418324328959\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 421, Loss: 0.030304493382573128\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 422, Loss: 0.030267311725765467\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 423, Loss: 0.0302302916534245\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 424, Loss: 0.03019343502819538\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 425, Loss: 0.03015673067420721\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 426, Loss: 0.030120186507701874\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 427, Loss: 0.030083796475082636\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 428, Loss: 0.03004756337031722\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 429, Loss: 0.030011483002454042\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 430, Loss: 0.029975559562444687\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 431, Loss: 0.02993978513404727\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 432, Loss: 0.02990416018292308\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 433, Loss: 0.02986868703737855\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 434, Loss: 0.029833367094397545\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 435, Loss: 0.029798186384141445\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 436, Loss: 0.02976315515115857\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 437, Loss: 0.02972828084602952\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 438, Loss: 0.029693543445318937\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 439, Loss: 0.029658949933946133\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 440, Loss: 0.02962450124323368\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 441, Loss: 0.029590196907520294\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 442, Loss: 0.029556038789451122\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 443, Loss: 0.029522013384848833\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 444, Loss: 0.029488140251487494\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 445, Loss: 0.029454390052706003\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 446, Loss: 0.029420788399875164\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 447, Loss: 0.029387321323156357\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 448, Loss: 0.029353994876146317\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 449, Loss: 0.029320801608264446\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 450, Loss: 0.0292877359315753\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 451, Loss: 0.02925481414422393\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 452, Loss: 0.029222024604678154\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 453, Loss: 0.029189362656325102\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 454, Loss: 0.029156836681067944\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 455, Loss: 0.02912443783134222\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 456, Loss: 0.029092174023389816\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 457, Loss: 0.02906003361567855\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 458, Loss: 0.029028032440692186\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 459, Loss: 0.028996150009334087\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 460, Loss: 0.028964394703507423\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 461, Loss: 0.02893276186659932\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 462, Loss: 0.02890126034617424\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 463, Loss: 0.02886988315731287\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 464, Loss: 0.02883863402530551\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 465, Loss: 0.028807499911636114\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 466, Loss: 0.028776487801223993\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 467, Loss: 0.02874560933560133\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 468, Loss: 0.02871484076604247\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 469, Loss: 0.02868418814614415\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 470, Loss: 0.02865366544574499\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 471, Loss: 0.02862326567992568\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 472, Loss: 0.028592973481863737\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 473, Loss: 0.028562796767801046\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 474, Loss: 0.028532748576253653\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 475, Loss: 0.028502807952463627\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 476, Loss: 0.028472985606640577\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 477, Loss: 0.02844328060746193\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 478, Loss: 0.028413680382072926\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 479, Loss: 0.028384202625602484\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 480, Loss: 0.028354837093502283\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 481, Loss: 0.02832557912915945\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 482, Loss: 0.028296437114477158\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 483, Loss: 0.028267402201890945\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 484, Loss: 0.028238479979336262\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 485, Loss: 0.028209663461893797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 07:38:56.013068: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 486, Loss: 0.0281809545122087\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 487, Loss: 0.028152361512184143\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 488, Loss: 0.02812387188896537\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 489, Loss: 0.0280954847112298\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 490, Loss: 0.028067211154848337\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 491, Loss: 0.028039041440933943\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 492, Loss: 0.028010974638164043\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 493, Loss: 0.027983015403151512\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 494, Loss: 0.027955162338912487\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 495, Loss: 0.02792740799486637\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 496, Loss: 0.027899758890271187\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 497, Loss: 0.027872197795659304\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 498, Loss: 0.027844758704304695\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n",
      "Epoch: 499, Loss: 0.027817409951239824\n",
      "Test acc: 0.9666666666666667\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 07:38:56.363896: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "data = load_iris()\n",
    "x_data = data.data\n",
    "y_data = data.target\n",
    "\n",
    "# \n",
    "np.random.seed(143)\n",
    "np.random.shuffle(x_data)\n",
    "np.random.seed(143)\n",
    "np.random.shuffle(y_data)\n",
    "tf.random.set_seed(143)\n",
    "\n",
    "# \n",
    "x_train = x_data[:-30]\n",
    "y_train = y_data[:-30]\n",
    "\n",
    "x_test = x_data[-30:]\n",
    "y_test = y_data[-30:]\n",
    "\n",
    "# \n",
    "x_train = tf.cast(x_train, dtype=tf.float32)\n",
    "x_test = tf.cast(x_test, dtype=tf.float32)\n",
    "\n",
    "# \n",
    "train_df = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_df = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "# \n",
    "w = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=143))\n",
    "b = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=143))\n",
    "\n",
    "# \n",
    "lr = 0.1\n",
    "epoch = 500\n",
    "\n",
    "# \n",
    "train_loss_result = []\n",
    "test_acc = []\n",
    "loss_all = 0\n",
    "\n",
    "# \n",
    "for epoch in range(epoch):\n",
    "    for step, (x_train, y_train) in enumerate(train_df):\n",
    "        # \n",
    "        with tf.GradientTape() as tape:\n",
    "            y = tf.matmul(x_train, w) + b\n",
    "            y = tf.nn.softmax(y)\n",
    "            \n",
    "            y_ = tf.one_hot(y_train, depth=3)\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.square(y - y_))\n",
    "            loss_all += loss.numpy()\n",
    "            \n",
    "        # \n",
    "        grads = tape.gradient(loss, [w, b])\n",
    "        \n",
    "        # \n",
    "        w.assign_sub(lr * grads[0])\n",
    "        b.assign_sub(lr * grads[1])\n",
    "        \n",
    "    print(f\"Epoch: {epoch}, Loss: {loss_all/4}\")\n",
    "    train_loss_result.append(loss_all/4)\n",
    "    loss_all = 0\n",
    "    \n",
    "    # \n",
    "    total_correct, total_number = 0, 0\n",
    "    for x_test, y_test in test_df:\n",
    "        y = tf.matmul(x_test, w) + b\n",
    "        y = tf.nn.softmax(y)\n",
    "        pred = tf.argmax(y, axis=1)\n",
    "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
    "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
    "        # batchcorrect\n",
    "        correct = tf.reduce_sum(correct) \n",
    "        total_correct += int(correct)\n",
    "        \n",
    "        total_number += x_test.shape[0]\n",
    "        \n",
    "    # \n",
    "    acc = total_correct / total_number\n",
    "    test_acc.append(acc)\n",
    "    print(\"Test acc:\", acc)\n",
    "    print(\"------------------\")\n",
    "    \n",
    "# loss\n",
    "plt.title(\"Loss Function Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(train_loss_result, label=\"$Loss$\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#  Accuracy\n",
    "plt.title(\"Acc Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.plot(test_acc, label=\"$Accuracy$\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baa64910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7be21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d39fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
